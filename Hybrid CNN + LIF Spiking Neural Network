# ==========================================================
# üß† Hybrid CNN + LIF Spiking Neural Network
# Neuromorphic Hand Gesture Classification
# ==========================================================

# ==============================
# 1Ô∏è‚É£ Import Required Libraries
# ==============================

import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    accuracy_score
)

import seaborn as sns
import matplotlib.pyplot as plt


# ==============================
# 2Ô∏è‚É£ Load Dataset
# ==============================

df = pd.read_csv("neuromorphic_hand_dataset_7400_samples.csv")

feature_cols = [
    "emg_adc","emg_rms",
    "flex_thumb","flex_index","flex_middle","flex_ring","flex_pinky",
    "fsr_thumb","fsr_index","fsr_middle",
    "spike_rate","membrane_potential","servo_angle"
]

X = df[feature_cols].values
y = df["gesture_id"].values - 1   # labels 0‚Äì36

# Normalize features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Convert to tensors
X_train = torch.tensor(X_train, dtype=torch.float32)
X_test  = torch.tensor(X_test, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.long)
y_test  = torch.tensor(y_test, dtype=torch.long)

# Add channel dimension for CNN
X_train = X_train.unsqueeze(1)
X_test  = X_test.unsqueeze(1)


# ==============================
# 3Ô∏è‚É£ LIF Spiking Layer
# ==============================

class LIFLayer(nn.Module):
    def __init__(self, size, threshold=1.0, decay=0.9):
        super().__init__()
        self.threshold = threshold
        self.decay = decay
        self.size = size

    def forward(self, input_current):
        batch_size = input_current.size(0)
        membrane = torch.zeros(batch_size, self.size).to(input_current.device)
        spikes = torch.zeros_like(membrane)

        time_steps = 10  # temporal spike simulation

        for t in range(time_steps):
            membrane = self.decay * membrane + input_current
            spike = (membrane >= self.threshold).float()
            membrane = membrane * (1 - spike)
            spikes += spike

        return spikes / time_steps


# ==============================
# 4Ô∏è‚É£ Hybrid CNN + SNN Model
# ==============================

class HybridCNNSNN(nn.Module):
    def __init__(self, num_classes=37):
        super().__init__()

        # CNN Feature Extractor
        self.cnn = nn.Sequential(
            nn.Conv1d(1, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv1d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Flatten(),
            nn.Linear(64 * 13, 128),
            nn.ReLU()
        )

        # LIF Layer
        self.lif = LIFLayer(128)

        # Output Layer
        self.fc = nn.Linear(128, num_classes)

    def forward(self, x):
        features = self.cnn(x)
        spike_output = self.lif(features)
        out = self.fc(spike_output)
        return out


# ==============================
# 5Ô∏è‚É£ Training Setup
# ==============================

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = HybridCNNSNN().to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

X_train, y_train = X_train.to(device), y_train.to(device)
X_test, y_test   = X_test.to(device), y_test.to(device)


# ==============================
# 6Ô∏è‚É£ Training Loop (UNCHANGED)
# ==============================

epochs = 25

for epoch in range(epochs):
    model.train()
    optimizer.zero_grad()

    outputs = model(X_train)
    loss = criterion(outputs, y_train)
    loss.backward()
    optimizer.step()

    model.eval()
    with torch.no_grad():
        test_outputs = model(X_test)
        _, predicted = torch.max(test_outputs, 1)
        accuracy = (predicted == y_test).float().mean()

    print(f"Epoch {epoch+1}/{epochs}, "
          f"Loss: {loss.item():.4f}, "
          f"Test Accuracy: {accuracy.item()*100:.2f}%")

print("Training Complete üöÄ")


# ==========================================================
# 7Ô∏è‚É£ Evaluation Metrics (ADDED SECTION)
# ==========================================================

model.eval()
with torch.no_grad():
    final_outputs = model(X_test)
    _, final_predicted = torch.max(final_outputs, 1)

y_true = y_test.cpu().numpy()
y_pred = final_predicted.cpu().numpy()

# ==============================
# üìä Accuracy
# ==============================

final_accuracy = accuracy_score(y_true, y_pred)
print(f"\nFinal Accuracy: {final_accuracy * 100:.2f}%")

# ==============================
# üìÑ Classification Report
# ==============================

report_dict = classification_report(
    y_true,
    y_pred,
    output_dict=True,
    zero_division=0
)

report_df = pd.DataFrame(report_dict).transpose()
report_df.to_excel("classification_report.xlsx", index=True)

print("Classification report saved as classification_report.xlsx")

# ==============================
# üìâ Confusion Matrix
# ==============================

cm = confusion_matrix(y_true, y_pred)

cm_df = pd.DataFrame(cm)
cm_df.to_excel("confusion_matrix.xlsx", index=False)

print("Confusion matrix saved as confusion_matrix.xlsx")

# Plot confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.savefig("confusion_matrix.png")
plt.show()

# ==============================
# üìå Macro Metrics
# ==============================

macro_precision = report_dict["macro avg"]["precision"]
macro_recall    = report_dict["macro avg"]["recall"]
macro_f1        = report_dict["macro avg"]["f1-score"]

print("\nüìå Overall Macro Metrics:")
print(f"Precision: {macro_precision:.4f}")
print(f"Recall:    {macro_recall:.4f}")
print(f"F1 Score:  {macro_f1:.4f}")
